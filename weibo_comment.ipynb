{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c897fa-69da-444c-88e6-754f7e5b5d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5957c9e-2585-430b-acea-eccf7b4575e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本数量（总体）：39105\n",
      "文本数量（0）：10225\n",
      "文本数量（1）：6760\n",
      "文本数量（1）：2849\n",
      "文本数量（2）：7877\n",
      "文本数量（3）：902\n",
      "文本数量（4）：3695\n",
      "文本数量（5）：5080\n",
      "文本数量（6）：1717\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = '/root/data/'\n",
    "comments = pd.read_csv(path + 'Train.csv',encoding='gb18030')\n",
    "comments_Labels = comments['Labels'].map(lambda x:x.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace('\"','')).replace(\" \",\"\").str.split(', ', expand=True)\n",
    "comments_Labels = comments_Labels.stack().reset_index(level=1, drop=True).rename('Labels')\n",
    "comments = comments.drop(['Labels'], axis=1).join(comments_Labels)\n",
    "comments = comments.dropna()\n",
    "moods = {'Love':0, 'Sorrow':1, 'Hate':1, 'Anxiety':2, 'Surprise':3, 'Expect':4, 'Joy':5, 'Anger':6}\n",
    "\n",
    "print('文本数量（总体）：%d' % comments.shape[0])\n",
    "for label, mood in moods.items(): \n",
    "    print('文本数量（{}）：{}'.format(mood,  comments[comments.Labels==label].shape[0]))\n",
    "\n",
    "comments.Labels = comments.Labels.map(moods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef4e0fc-8206-47af-b9cf-a6613f55dfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>她们 都 睡 蹑手蹑脚 摸黑 上 床 凑 上 去 想 亲 嫣 一下 她 突然 一个 转身 小...</td>\n",
       "      <td>['Love', 'Joy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>现在 好 终于 如愿以偿</td>\n",
       "      <td>['Joy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>感受 着 小手 温度 享受 着 这份 她 对 我的 依恋 生怕 动 一下 会 让 她 小手 ...</td>\n",
       "      <td>['Love', 'Joy', 'Anxiety']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>望 一眼 背 身 而 卧 妻 如果 她 知道 我的 想法 一定 又 会 那 句 ： 切 又 ...</td>\n",
       "      <td>['Love', 'Anxiety']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>眼睛 逐渐 适应 周围 黑暗 借 着 床头 热 奶 器 上 桔红色 指示灯 微弱 光线 慢慢...</td>\n",
       "      <td>['Love', 'Joy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25995</th>\n",
       "      <td>25996</td>\n",
       "      <td>宗林 生活 不会 停止 思想 上 不 会 停止 创新 上 不 会 停止</td>\n",
       "      <td>['Love', 'Expect']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25996</th>\n",
       "      <td>25997</td>\n",
       "      <td>开头 他 拿 来 写的 散文 读 刮目相看 还 挑选 篇 刊发 美文 杂志 上 不久 他 又...</td>\n",
       "      <td>['Love']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25997</th>\n",
       "      <td>25998</td>\n",
       "      <td>宗林 一个 好 男人 但 好 男人 也 不幸 遭遇</td>\n",
       "      <td>['Sorrow']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25998</th>\n",
       "      <td>25999</td>\n",
       "      <td>本来 他 美丽 贤惠 妻子 一个 温暖 可意 家庭 谁 也 没 想到 妻子 患 绝症 竟 于...</td>\n",
       "      <td>['Sorrow']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25999</th>\n",
       "      <td>26000</td>\n",
       "      <td>宗林 对 妻子 守护 和 送别 感动 许多 朋友</td>\n",
       "      <td>['Love', 'Sorrow']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                               Text  \\\n",
       "0          1  她们 都 睡 蹑手蹑脚 摸黑 上 床 凑 上 去 想 亲 嫣 一下 她 突然 一个 转身 小...   \n",
       "1          2                                       现在 好 终于 如愿以偿   \n",
       "2          3  感受 着 小手 温度 享受 着 这份 她 对 我的 依恋 生怕 动 一下 会 让 她 小手 ...   \n",
       "3          4  望 一眼 背 身 而 卧 妻 如果 她 知道 我的 想法 一定 又 会 那 句 ： 切 又 ...   \n",
       "4          5  眼睛 逐渐 适应 周围 黑暗 借 着 床头 热 奶 器 上 桔红色 指示灯 微弱 光线 慢慢...   \n",
       "...      ...                                                ...   \n",
       "25995  25996                宗林 生活 不会 停止 思想 上 不 会 停止 创新 上 不 会 停止   \n",
       "25996  25997  开头 他 拿 来 写的 散文 读 刮目相看 还 挑选 篇 刊发 美文 杂志 上 不久 他 又...   \n",
       "25997  25998                          宗林 一个 好 男人 但 好 男人 也 不幸 遭遇   \n",
       "25998  25999  本来 他 美丽 贤惠 妻子 一个 温暖 可意 家庭 谁 也 没 想到 妻子 患 绝症 竟 于...   \n",
       "25999  26000                           宗林 对 妻子 守护 和 送别 感动 许多 朋友   \n",
       "\n",
       "                           Labels  \n",
       "0                 ['Love', 'Joy']  \n",
       "1                         ['Joy']  \n",
       "2      ['Love', 'Joy', 'Anxiety']  \n",
       "3             ['Love', 'Anxiety']  \n",
       "4                 ['Love', 'Joy']  \n",
       "...                           ...  \n",
       "25995          ['Love', 'Expect']  \n",
       "25996                    ['Love']  \n",
       "25997                  ['Sorrow']  \n",
       "25998                  ['Sorrow']  \n",
       "25999          ['Love', 'Sorrow']  \n",
       "\n",
       "[26000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = '/root/data/'\n",
    "train = pd.read_csv(path + 'Train.csv',encoding='gb18030')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5867335-fdd8-4c95-b05c-75c5a43df684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>天 哪 她 还 真 以为 她 名画家</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>真 朋友 无功 利 心 真心 相待 ； 假 朋友 表面 上 逢迎 拍马 暗地里 下绊 子 使坏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>真的 好 累 好 累 想 休息 写下 文字</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>湿淋淋 头发 隔 着 毛衣 凉 背心</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>我不 高手 呦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>6149</td>\n",
       "      <td>再说 拐弯 让 直行 次 右 拐 同方向 直行 车 没有 走 完 我在 等待 后面 车 就 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>6150</td>\n",
       "      <td>这才 一个 学生 应有 面容 呀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>6151</td>\n",
       "      <td>坐下 随着 这 声 命令 同学 们 七零八落 地 坐下</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>6152</td>\n",
       "      <td>又 周末 去 城内 四 府 街 陈 老师 家里 送 代购 几 本 书 蒙 他 厚爱 再 赠 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>6153</td>\n",
       "      <td>刚 开学 一星期 嗓子 就 已经 坏 掉</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text\n",
       "0        1                                 天 哪 她 还 真 以为 她 名画家\n",
       "1        2    真 朋友 无功 利 心 真心 相待 ； 假 朋友 表面 上 逢迎 拍马 暗地里 下绊 子 使坏\n",
       "2        3                              真的 好 累 好 累 想 休息 写下 文字\n",
       "3        4                                 湿淋淋 头发 隔 着 毛衣 凉 背心\n",
       "4        5                                            我不 高手 呦\n",
       "...    ...                                                ...\n",
       "6148  6149  再说 拐弯 让 直行 次 右 拐 同方向 直行 车 没有 走 完 我在 等待 后面 车 就 ...\n",
       "6149  6150                                   这才 一个 学生 应有 面容 呀\n",
       "6150  6151                        坐下 随着 这 声 命令 同学 们 七零八落 地 坐下\n",
       "6151  6152  又 周末 去 城内 四 府 街 陈 老师 家里 送 代购 几 本 书 蒙 他 厚爱 再 赠 ...\n",
       "6152  6153                               刚 开学 一星期 嗓子 就 已经 坏 掉\n",
       "\n",
       "[6153 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = '/root/data/'\n",
    "test = pd.read_csv(path + 'test.csv',encoding='gb18030')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59cbdf8e-2825-4570-9738-a0095c29e2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085c25d1-5f50-40b7-bc1a-d4cb1d064ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Expect</th>\n",
       "      <th>Hate</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Love</th>\n",
       "      <th>Sorrow</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>她们 都 睡 蹑手蹑脚 摸黑 上 床 凑 上 去 想 亲 嫣 一下 她 突然 一个 转身 小...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>现在 好 终于 如愿以偿</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>感受 着 小手 温度 享受 着 这份 她 对 我的 依恋 生怕 动 一下 会 让 她 小手 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>望 一眼 背 身 而 卧 妻 如果 她 知道 我的 想法 一定 又 会 那 句 ： 切 又 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>眼睛 逐渐 适应 周围 黑暗 借 着 床头 热 奶 器 上 桔红色 指示灯 微弱 光线 慢慢...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25995</th>\n",
       "      <td>25996</td>\n",
       "      <td>宗林 生活 不会 停止 思想 上 不 会 停止 创新 上 不 会 停止</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25996</th>\n",
       "      <td>25997</td>\n",
       "      <td>开头 他 拿 来 写的 散文 读 刮目相看 还 挑选 篇 刊发 美文 杂志 上 不久 他 又...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25997</th>\n",
       "      <td>25998</td>\n",
       "      <td>宗林 一个 好 男人 但 好 男人 也 不幸 遭遇</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25998</th>\n",
       "      <td>25999</td>\n",
       "      <td>本来 他 美丽 贤惠 妻子 一个 温暖 可意 家庭 谁 也 没 想到 妻子 患 绝症 竟 于...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25999</th>\n",
       "      <td>26000</td>\n",
       "      <td>宗林 对 妻子 守护 和 送别 感动 许多 朋友</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                               Text  Anger  \\\n",
       "0          1  她们 都 睡 蹑手蹑脚 摸黑 上 床 凑 上 去 想 亲 嫣 一下 她 突然 一个 转身 小...      0   \n",
       "1          2                                       现在 好 终于 如愿以偿      0   \n",
       "2          3  感受 着 小手 温度 享受 着 这份 她 对 我的 依恋 生怕 动 一下 会 让 她 小手 ...      0   \n",
       "3          4  望 一眼 背 身 而 卧 妻 如果 她 知道 我的 想法 一定 又 会 那 句 ： 切 又 ...      0   \n",
       "4          5  眼睛 逐渐 适应 周围 黑暗 借 着 床头 热 奶 器 上 桔红色 指示灯 微弱 光线 慢慢...      0   \n",
       "...      ...                                                ...    ...   \n",
       "25995  25996                宗林 生活 不会 停止 思想 上 不 会 停止 创新 上 不 会 停止      0   \n",
       "25996  25997  开头 他 拿 来 写的 散文 读 刮目相看 还 挑选 篇 刊发 美文 杂志 上 不久 他 又...      0   \n",
       "25997  25998                          宗林 一个 好 男人 但 好 男人 也 不幸 遭遇      0   \n",
       "25998  25999  本来 他 美丽 贤惠 妻子 一个 温暖 可意 家庭 谁 也 没 想到 妻子 患 绝症 竟 于...      0   \n",
       "25999  26000                           宗林 对 妻子 守护 和 送别 感动 许多 朋友      0   \n",
       "\n",
       "       Anxiety  Expect  Hate  Joy  Love  Sorrow  Surprise  \n",
       "0            0       0     0    1     1       0         0  \n",
       "1            0       0     0    1     0       0         0  \n",
       "2            1       0     0    1     1       0         0  \n",
       "3            1       0     0    0     1       0         0  \n",
       "4            0       0     0    1     1       0         0  \n",
       "...        ...     ...   ...  ...   ...     ...       ...  \n",
       "25995        0       1     0    0     1       0         0  \n",
       "25996        0       0     0    0     1       0         0  \n",
       "25997        0       0     0    0     0       1         0  \n",
       "25998        0       0     0    0     0       1         0  \n",
       "25999        0       0     0    0     1       1         0  \n",
       "\n",
       "[26000 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Labels'] = train['Labels'].apply(eval)\n",
    "train = train.join(train['Labels'].str.join('|').str.get_dummies())\n",
    "train = train.drop('Labels', axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e01e80-0c09-45db-a806-82a7d7594e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5a4535-57fd-4bc0-b033-6e23936d8e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26000 entries, 0 to 25999\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   ID        26000 non-null  int64 \n",
      " 1   Text      26000 non-null  object\n",
      " 2   Anger     26000 non-null  int64 \n",
      " 3   Anxiety   26000 non-null  int64 \n",
      " 4   Expect    26000 non-null  int64 \n",
      " 5   Hate      26000 non-null  int64 \n",
      " 6   Joy       26000 non-null  int64 \n",
      " 7   Love      26000 non-null  int64 \n",
      " 8   Sorrow    26000 non-null  int64 \n",
      " 9   Surprise  26000 non-null  int64 \n",
      "dtypes: int64(9), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5b93c5f-808a-4c76-a8e7-c21f68397502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e921c06e-ca8e-4bc2-9816-6cbc3c81a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb0c35c5-d2b0-4150-a196-8a492568c5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['more i can t make any real suggestions on improvement i wondered if the section statistics should be later on or a subsection of types of accidents i think the references may need tidying so that they are all in the exact same format ie date format etc i can do that later on if no one else does first if you have any preferences for formatting style on references or want to do it yourself please let me know there appears to be a backlog on articles for review so i guess there may be a delay until a reviewer turns up it s listed in the relevant form eg wikipedia good article nominations transport']\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    # Remove web links\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "\n",
    "    # Remove special characters, punctuation marks, and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "\n",
    "    # Insert spaces between certain patterns (e.g., \"ie\", \"eg\")\n",
    "    text = re.sub(r'(\\s)([iI][eE]|[eE][gG])(\\s)', r' \\2 ', text)\n",
    "\n",
    "    # Remove extra white spaces\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "# Example usage with the provided text\n",
    "texts = [\n",
    "    \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of 'types of accidents'  -I think the references may need tidying so that they are all in the exact same format ie date format etc I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport\"\n",
    "]\n",
    "\n",
    "cleaned_texts = [clean_text(text) for text in texts]\n",
    "print(cleaned_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2f48f1-a618-461c-8b6b-7997963d4c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anger', 'Anxiety', 'Expect', 'Hate', 'Joy', 'Love', 'Sorrow', 'Surprise']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_labels= [col for col in train.columns if train[col].dtypes == 'int64' and train[col].name!='ID']\n",
    "target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3511ab90-9784-443c-9cf8-a2e0f80bb878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate word cloud\n",
    "def generate_wordcloud(text,Title):\n",
    "    wordcloud = WordCloud(width=800, height=400,stopwords=set(STOPWORDS), background_color='black').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(Title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eaa413e-d8fa-4aa7-9c8c-d9aad15dc8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['她们 都 睡 蹑手蹑脚 摸黑 上 床 凑 上 去 想 亲 嫣 一下 她 突然 一个 转身 小手 啪 地 搭 我的 脸颊 上 我便 被 施 魔法 似地 定 住 每次 抱 着 嫣 时候 总想 让 她 小手 搂 着 我的 脖子 可 她 总是 不肯 她 只 小手 指挥 着 我的 方向 指 着 她 感 兴趣 东西 一刻 也 不肯 停 闲',\n",
       " '现在 好 终于 如愿以偿',\n",
       " '感受 着 小手 温度 享受 着 这份 她 对 我的 依恋 生怕 动 一下 会 让 她 小手 离 而 去',\n",
       " '望 一眼 背 身 而 卧 妻 如果 她 知道 我的 想法 一定 又 会 那 句 ： 切 又 自作 多 情',\n",
       " '眼睛 逐渐 适应 周围 黑暗 借 着 床头 热 奶 器 上 桔红色 指示灯 微弱 光线 慢慢 能 看见 她们 轮廓 能 听见 她们 呼吸 天 疲惫 瞬间 不再 难得 一刻 清静']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments=train['Text'].to_list()\n",
    "comments[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a73b1110-6563-4f7d-bc58-c34fa9da9f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['天 哪 她 还 真 以为 她 名画家',\n",
       " '真 朋友 无功 利 心 真心 相待 ； 假 朋友 表面 上 逢迎 拍马 暗地里 下绊 子 使坏',\n",
       " '真的 好 累 好 累 想 休息 写下 文字',\n",
       " '湿淋淋 头发 隔 着 毛衣 凉 背心',\n",
       " '我不 高手 呦']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_test=test['Text'].to_list()\n",
    "comments_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42626ad2-8691-4bad-bda1-c55538d1e36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset --> 18200 (18200, 8)\n",
      "Testing Dataset --> 5304 (5304, 8)\n",
      "validation Dataset --> 2496 (2496, 8)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training, testing sets & validation sets \n",
    "Train_texts, Test_texts, Train_labels, Test_labels = train_test_split(\n",
    "    comments, train[target_labels].values, test_size=0.3, random_state=50)\n",
    "\n",
    "#validation set\n",
    "test_texts, val_texts, test_labels, val_labels = train_test_split(\n",
    "    Test_texts, Test_labels, test_size=0.32, random_state=23)\n",
    "\n",
    "print('Training Dataset -->',len(Train_texts), Train_labels.shape)\n",
    "print('Testing Dataset -->',len(test_texts), test_labels.shape)\n",
    "print('validation Dataset -->',len(val_texts), val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "108f8683-233d-47c9-9aed-931302b3f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(tokenizer, comments, labels, max_length=128):\n",
    "    # Initialize empty lists to store tokenized inputs and attention masks\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # Iterate through each comment in the 'comments' list\n",
    "    for comment in comments:\n",
    "        # Tokenize and encode the comment using the BERT tokenizer\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            comment,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Append the tokenized input and attention mask to their respective lists\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists of tokenized inputs and attention masks to PyTorch tensors\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    # Convert the labels to a PyTorch tensor with the data type float32\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    # Return the tokenized inputs, attention masks, and labels as PyTorch tensors\n",
    "    return input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dccbbc0-ae9c-47a1-8552-f32a229d01bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 1921, 1525,  ...,    0,    0,    0],\n",
       "         [ 101, 4696, 3301,  ...,    0,    0,    0],\n",
       "         [ 101, 4696, 4638,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 1777,  678,  ...,    0,    0,    0],\n",
       "         [ 101, 1348, 1453,  ...,    0,    0,    0],\n",
       "         [ 101, 1157, 2458,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comments_test\n",
    "input_ids_test, attention_masks_test, labels = tokenize_and_encode(\n",
    "    tokenizer, \n",
    "    comments_test, \n",
    "    []\n",
    ")\n",
    "input_ids_test, attention_masks_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2021ad0e-822f-4b84-aa66-39a8bb2a541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./model/bert-base-chinese and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([7, 768]) in the checkpoint and torch.Size([8, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([7]) in the checkpoint and torch.Size([8]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Token Initialization\n",
    "tokenizer = BertTokenizer.from_pretrained('./model/bert-base-chinese', do_lower_case=True)\n",
    "\n",
    "# Model Initialization\n",
    "model = BertForSequenceClassification.from_pretrained('./model/bert-base-chinese', num_labels=8, ignore_mismatched_sizes=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b2fd277-934a-4242-a82a-a09de7555339",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "333e396b-b50e-4bee-b8e0-48e4113bb444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "model =model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8650ef27-167b-4f67-91e0-6a9d7f12f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Comments : 18200\n",
      "Input Ids         : torch.Size([18200, 128])\n",
      "Attention Mask    : torch.Size([18200, 128])\n",
      "Labels            : torch.Size([18200, 8])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and Encode the comments and labels for the training set\n",
    "input_ids, attention_masks, labels = tokenize_and_encode(\n",
    "    tokenizer, \n",
    "    Train_texts, \n",
    "    Train_labels\n",
    ")\n",
    "\n",
    "# Step 4: Tokenize and Encode the comments and labels for the test set\n",
    "test_input_ids, test_attention_masks, test_labels = tokenize_and_encode(\n",
    "    tokenizer,\n",
    "    test_texts,\n",
    "    test_labels\n",
    ")\n",
    "\n",
    "# Tokenize and Encode the comments and labels for the validation set\n",
    "val_input_ids, val_attention_masks, val_labels = tokenize_and_encode(\n",
    "    tokenizer,\n",
    "    val_texts,\n",
    "    val_labels\n",
    ")\n",
    "\n",
    "print('Training Comments :',len(Train_texts))\n",
    "print('Input Ids         :',input_ids.shape)\n",
    "print('Attention Mask    :',attention_masks.shape)\n",
    "print('Labels            :',labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e4a0547-af88-4a57-baea-ed82642e6d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Comments -->> 这 消息 太 突然 太 叫 人 接受 不 不 说 好人 一生 平安 吗\n",
      "\n",
      "Input Ids -->>\n",
      " tensor([ 101, 6821, 3867, 2622, 1922, 4960, 4197, 1922, 1373,  782, 2970, 1358,\n",
      "         679,  679, 6432, 1962,  782,  671, 4495, 2398, 2128, 1408,  102,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "\n",
      "Decoded Ids -->>\n",
      " [CLS] 这 消 息 太 突 然 太 叫 人 接 受 不 不 说 好 人 一 生 平 安 吗 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "\n",
      "Attention Mask -->>\n",
      " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "Labels -->> tensor([0., 1., 0., 0., 0., 0., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "k = 523\n",
    "print('Training Comments -->>',Train_texts[k])\n",
    "print('\\nInput Ids -->>\\n',input_ids[k])\n",
    "print('\\nDecoded Ids -->>\\n',tokenizer.decode(input_ids[k]))\n",
    "print('\\nAttention Mask -->>\\n',attention_masks[k])\n",
    "print('\\nLabels -->>',labels[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e2d04e4-2331-455d-a101-ce214855f984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47e0f445-0df5-4713-a1ca-beda5095c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataLoader for the balanced dataset\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#test\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#val\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c03166d-86ad-43f6-959e-50c82b6932c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18200, 568.75, 165.75, 78.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset),len(train_dataset)/batch_size,len(test_dataset)/batch_size,len(val_dataset)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9a12ae8-0aff-4f87-9c7a-7922028859c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size : 32\n",
      "Each Input ids shape : torch.Size([32, 128])\n",
      "Input ids :\n",
      " tensor([ 101,  704, 1744,  837, 5320, 2157, 1072,  704, 1744, 2471, 6629, 2408,\n",
      "        3793, 7028, 6228,  679, 6814, 2457,  865, 2399,  752, 2658,  102,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Corresponding Decoded text:\n",
      " [CLS] 中 国 传 统 家 具 中 国 引 起 广 泛 重 视 不 过 廿 余 年 事 情 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Corresponding Attention Mask :\n",
      " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Corresponding Label: tensor([0., 0., 0., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print('Batch Size :',train_loader.batch_size)\n",
    "Batch =next(iter(train_loader))\n",
    "print('Each Input ids shape :',Batch[0].shape)\n",
    "print('Input ids :\\n',Batch[0][0])\n",
    "print('Corresponding Decoded text:\\n',tokenizer.decode(Batch[0][0]))\n",
    "print('Corresponding Attention Mask :\\n',Batch[1][0])\n",
    "print('Corresponding Label:',Batch[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "522c9832-c181-4111-8da0-2a8f63b71b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer setup\n",
    "optimizer = AdamW(model.parameters(), lr=0.00002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e729c9e9-7527-444d-b306-8d4c883e2df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.18121593306741313, Validation Loss: 0.2747217573416539\n",
      "Epoch 2, Training Loss: 0.14439380598403448, Validation Loss: 0.28969834993282956\n",
      "Epoch 3, Training Loss: 0.11303724463773737, Validation Loss: 0.3204476489470555\n",
      "Epoch 4, Training Loss: 0.08693034916801905, Validation Loss: 0.34964302755319154\n",
      "Epoch 5, Training Loss: 0.06913524469678242, Validation Loss: 0.3933856447155659\n",
      "Epoch 6, Training Loss: 0.05371765102470958, Validation Loss: 0.4004038159663861\n",
      "Epoch 7, Training Loss: 0.04434959989807099, Validation Loss: 0.431045800447464\n",
      "Epoch 8, Training Loss: 0.03595339406530499, Validation Loss: 0.45247360605459946\n",
      "Epoch 9, Training Loss: 0.03199982963770837, Validation Loss: 0.4755172523168417\n",
      "Epoch 10, Training Loss: 0.02833502842211582, Validation Loss: 0.4889264903389491\n",
      "Epoch 11, Training Loss: 0.025482095729703697, Validation Loss: 0.5068318710113183\n",
      "Epoch 12, Training Loss: 0.022392986091884975, Validation Loss: 0.519519376831177\n",
      "Epoch 13, Training Loss: 0.02160983131903834, Validation Loss: 0.5324552074456826\n",
      "Epoch 14, Training Loss: 0.020119796446090816, Validation Loss: 0.5351130584111581\n",
      "Epoch 15, Training Loss: 0.019154287113191032, Validation Loss: 0.5481215470876449\n",
      "Epoch 16, Training Loss: 0.019166764696022277, Validation Loss: 0.5678870563323681\n",
      "Epoch 17, Training Loss: 0.01708105751820668, Validation Loss: 0.5635958902346783\n",
      "Epoch 18, Training Loss: 0.015231345454067227, Validation Loss: 0.5683114715875723\n",
      "Epoch 19, Training Loss: 0.015200294842100613, Validation Loss: 0.5906734768396769\n",
      "Epoch 20, Training Loss: 0.014875864935997933, Validation Loss: 0.5869473906663748\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs):\n",
    "    # Loop through the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to training mode\n",
    "        model.train() \n",
    "        # Initialize total loss for the current epoch\n",
    "        total_loss = 0  \n",
    "\n",
    "        # Loop through the batches in the training data\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "            # print(len(input_ids),len(input_ids))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # if labels.size()[0] != batch_size:\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0\n",
    "\n",
    "        # Disable gradient computation during validation\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "                # if labels.size()[0] != batch_size:\n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Print the average loss for the current epoch\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {total_loss/len(train_loader)}, Validation Loss: {val_loss/len(val_loader)}')\n",
    "\n",
    "# Assuming you have 'train_loader' and 'val_loader' defined elsewhere\n",
    "# Call the function to train the model\n",
    "train_model(model, train_loader, val_loader, optimizer, device, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35cf60fc-0533-487e-95da-92248d8b2981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3963\n",
      "Precision: 0.6863\n",
      "Recall: 0.6481\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the Model\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = [t.to(device) for t in batch]\n",
    "\n",
    "            # Get model's predictions\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predicted_probs_batch = torch.sigmoid(outputs.logits)  # Use sigmoid for multilabel classification\n",
    "            predicted_probs.append(predicted_probs_batch.cpu().numpy())\n",
    "\n",
    "            true_labels_batch = labels.cpu().numpy()\n",
    "            true_labels.append(true_labels_batch)\n",
    "\n",
    "    # Combine predictions and labels for evaluation\n",
    "    true_labels = np.concatenate(true_labels, axis=0)\n",
    "    predicted_probs = np.concatenate(predicted_probs, axis=0)\n",
    "    predicted_labels = (predicted_probs > 0.5).astype(int)  # Apply threshold for binary classification\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='micro')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='micro')\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Call the function to evaluate the model on the test data\n",
    "evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c766bfca-6a5c-41d9-a2b8-289c4ece77c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./Saved_model/tokenizer_config.json',\n",
       " './Saved_model/special_tokens_map.json',\n",
       " './Saved_model/vocab.txt',\n",
       " './Saved_model/added_tokens.json')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the tokenizer and model in the same directory\n",
    "output_dir = \"./Saved_model\"\n",
    "model.save_pretrained(output_dir)  # Save model's state dictionary and configuration\n",
    "tokenizer.save_pretrained(output_dir)  # Save tokenizer's configuration and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "746f8a60-0774-421e-b14e-a18b42fc1254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>天 哪 她 还 真 以为 她 名画家</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>真 朋友 无功 利 心 真心 相待 ； 假 朋友 表面 上 逢迎 拍马 暗地里 下绊 子 使坏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>真的 好 累 好 累 想 休息 写下 文字</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>湿淋淋 头发 隔 着 毛衣 凉 背心</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>我不 高手 呦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>6149</td>\n",
       "      <td>再说 拐弯 让 直行 次 右 拐 同方向 直行 车 没有 走 完 我在 等待 后面 车 就 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>6150</td>\n",
       "      <td>这才 一个 学生 应有 面容 呀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>6151</td>\n",
       "      <td>坐下 随着 这 声 命令 同学 们 七零八落 地 坐下</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>6152</td>\n",
       "      <td>又 周末 去 城内 四 府 街 陈 老师 家里 送 代购 几 本 书 蒙 他 厚爱 再 赠 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>6153</td>\n",
       "      <td>刚 开学 一星期 嗓子 就 已经 坏 掉</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text\n",
       "0        1                                 天 哪 她 还 真 以为 她 名画家\n",
       "1        2    真 朋友 无功 利 心 真心 相待 ； 假 朋友 表面 上 逢迎 拍马 暗地里 下绊 子 使坏\n",
       "2        3                              真的 好 累 好 累 想 休息 写下 文字\n",
       "3        4                                 湿淋淋 头发 隔 着 毛衣 凉 背心\n",
       "4        5                                            我不 高手 呦\n",
       "...    ...                                                ...\n",
       "6148  6149  再说 拐弯 让 直行 次 右 拐 同方向 直行 车 没有 走 完 我在 等待 后面 车 就 ...\n",
       "6149  6150                                   这才 一个 学生 应有 面容 呀\n",
       "6150  6151                        坐下 随着 这 声 命令 同学 们 七零八落 地 坐下\n",
       "6151  6152  又 周末 去 城内 四 府 街 陈 老师 家里 送 代购 几 本 书 蒙 他 厚爱 再 赠 ...\n",
       "6152  6153                               刚 开学 一星期 嗓子 就 已经 坏 掉\n",
       "\n",
       "[6153 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = '/root/data/'\n",
    "test = pd.read_csv(path + 'test.csv',encoding='gb18030')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9992d2b-e774-4d75-99b4-609507552e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d266d75f-dda1-4f77-9f93-3864ed292a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['天 哪 她 还 真 以为 她 名画家',\n",
       " '真 朋友 无功 利 心 真心 相待 ； 假 朋友 表面 上 逢迎 拍马 暗地里 下绊 子 使坏',\n",
       " '真的 好 累 好 累 想 休息 写下 文字',\n",
       " '湿淋淋 头发 隔 着 毛衣 凉 背心',\n",
       " '我不 高手 呦']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_test=test['Text'].to_list()\n",
    "comments_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "868b406b-0400-4bc8-8fbc-f8a882267d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 101, 1921, 1525,  ...,    0,    0,    0],\n",
       "         [ 101, 4696, 3301,  ...,    0,    0,    0],\n",
       "         [ 101, 4696, 4638,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 1777,  678,  ...,    0,    0,    0],\n",
       "         [ 101, 1348, 1453,  ...,    0,    0,    0],\n",
       "         [ 101, 1157, 2458,  ...,    0,    0,    0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comments_test\n",
    "input_ids_test, attention_masks_test, labels = tokenize_and_encode(\n",
    "    tokenizer, \n",
    "    comments_test, \n",
    "    []\n",
    ")\n",
    "input_ids_test, attention_masks_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f877d40-0336-484e-92b5-1ce2f3b2fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([1]).unsqueeze(0)\n",
    "test_dataset = TensorDataset(input_ids_test, attention_masks_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "380df268-f2db-45d1-b4ca-45becec5cbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8e1f83ba-d0d4-4151-9785-08ba43cf4619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f2151daf-7dda-47b5-94b8-94a34d764bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "true_labels = []\n",
    "predicted_probs = []\n",
    "predicted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "064f9d51-d907-4539-8271-29c4eeef3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask = [t.to(device) for t in batch]\n",
    "            i=i+1\n",
    "            # print(input_ids.size())\n",
    "\n",
    "            # Get model's predictions\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predicted_probs_batch = torch.sigmoid(outputs.logits)  # Use sigmoid for multilabel classification\n",
    "            predicted_probs.append(predicted_probs_batch.cpu().numpy())\n",
    "\n",
    "\n",
    "# Combine predictions and labels for evaluation\n",
    "predicted_probs = np.concatenate(predicted_probs, axis=0)\n",
    "predicted_labels = (predicted_probs > 0.5).astype(int)  # Apply threshold for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3bc6e80e-6f7d-4985-b5a7-c26d4b93ae3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "57eb12b7-a95a-4301-89d4-46ae7936c1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6153 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7\n",
       "0     0  0  1  0  0  0  0  0\n",
       "1     0  0  1  0  0  0  0  0\n",
       "2     1  1  0  0  0  0  0  0\n",
       "3     1  1  0  1  0  0  0  0\n",
       "4     0  0  0  0  0  0  1  0\n",
       "...  .. .. .. .. .. .. .. ..\n",
       "6148  0  0  0  0  0  1  0  0\n",
       "6149  0  0  1  0  0  1  0  0\n",
       "6150  0  0  0  0  1  1  0  0\n",
       "6151  0  1  0  0  0  0  0  0\n",
       "6152  0  1  0  0  0  0  0  0\n",
       "\n",
       "[6153 rows x 8 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = pd.DataFrame(predicted_labels)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "40d01c54-5d5e-4ebd-a27f-2b1b492ef866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Expect</th>\n",
       "      <th>Hate</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Love</th>\n",
       "      <th>Sorrow</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6153 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Anger  Anxiety  Expect  Hate  Joy  Love  Sorrow  Surprise\n",
       "0         0        0       1     0    0     0       0         0\n",
       "1         0        0       1     0    0     0       0         0\n",
       "2         1        1       0     0    0     0       0         0\n",
       "3         1        1       0     1    0     0       0         0\n",
       "4         0        0       0     0    0     0       1         0\n",
       "...     ...      ...     ...   ...  ...   ...     ...       ...\n",
       "6148      0        0       0     0    0     1       0         0\n",
       "6149      0        0       1     0    0     1       0         0\n",
       "6150      0        0       0     0    1     1       0         0\n",
       "6151      0        1       0     0    0     0       0         0\n",
       "6152      0        1       0     0    0     0       0         0\n",
       "\n",
       "[6153 rows x 8 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels.columns = target_labels\n",
    "# predicted_labels = predicted_labels.rename(columns={'0':'Anger', '1':'Anxiety', '2':'Expect','3':'Hate', '4':'Joy', '5':'Love', '6':'Sorrow','7':'Surprise'})\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "81d5e519-892c-45df-bc6f-f5d11a834380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Expect</th>\n",
       "      <th>Hate</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Love</th>\n",
       "      <th>Sorrow</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>天 哪 她 还 真 以为 她 名画家</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>真 朋友 无功 利 心 真心 相待 ； 假 朋友 表面 上 逢迎 拍马 暗地里 下绊 子 使坏</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>真的 好 累 好 累 想 休息 写下 文字</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>湿淋淋 头发 隔 着 毛衣 凉 背心</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>我不 高手 呦</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>6149</td>\n",
       "      <td>再说 拐弯 让 直行 次 右 拐 同方向 直行 车 没有 走 完 我在 等待 后面 车 就 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>6150</td>\n",
       "      <td>这才 一个 学生 应有 面容 呀</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>6151</td>\n",
       "      <td>坐下 随着 这 声 命令 同学 们 七零八落 地 坐下</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>6152</td>\n",
       "      <td>又 周末 去 城内 四 府 街 陈 老师 家里 送 代购 几 本 书 蒙 他 厚爱 再 赠 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>6153</td>\n",
       "      <td>刚 开学 一星期 嗓子 就 已经 坏 掉</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6153 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                               Text  Anger  Anxiety  \\\n",
       "0        1                                 天 哪 她 还 真 以为 她 名画家      0        0   \n",
       "1        2    真 朋友 无功 利 心 真心 相待 ； 假 朋友 表面 上 逢迎 拍马 暗地里 下绊 子 使坏      0        0   \n",
       "2        3                              真的 好 累 好 累 想 休息 写下 文字      1        1   \n",
       "3        4                                 湿淋淋 头发 隔 着 毛衣 凉 背心      1        1   \n",
       "4        5                                            我不 高手 呦      0        0   \n",
       "...    ...                                                ...    ...      ...   \n",
       "6148  6149  再说 拐弯 让 直行 次 右 拐 同方向 直行 车 没有 走 完 我在 等待 后面 车 就 ...      0        0   \n",
       "6149  6150                                   这才 一个 学生 应有 面容 呀      0        0   \n",
       "6150  6151                        坐下 随着 这 声 命令 同学 们 七零八落 地 坐下      0        0   \n",
       "6151  6152  又 周末 去 城内 四 府 街 陈 老师 家里 送 代购 几 本 书 蒙 他 厚爱 再 赠 ...      0        1   \n",
       "6152  6153                               刚 开学 一星期 嗓子 就 已经 坏 掉      0        1   \n",
       "\n",
       "      Expect  Hate  Joy  Love  Sorrow  Surprise  \n",
       "0          1     0    0     0       0         0  \n",
       "1          1     0    0     0       0         0  \n",
       "2          0     0    0     0       0         0  \n",
       "3          0     1    0     0       0         0  \n",
       "4          0     0    0     0       1         0  \n",
       "...      ...   ...  ...   ...     ...       ...  \n",
       "6148       0     0    0     1       0         0  \n",
       "6149       1     0    0     1       0         0  \n",
       "6150       0     0    1     1       0         0  \n",
       "6151       0     0    0     0       0         0  \n",
       "6152       0     0    0     0       0         0  \n",
       "\n",
       "[6153 rows x 10 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test['ID'].join(predicted_labels)\n",
    "test1 = pd.concat([test,predicted_labels], axis=1)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b9951145-1e34-4213-a53b-2fb0c0340653",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.to_csv('./test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b62e553-9b85-4cb6-bb76-396c50bdbbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Expect</th>\n",
       "      <th>Hate</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Love</th>\n",
       "      <th>Sorrow</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>6148</td>\n",
       "      <td>6149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>6149</td>\n",
       "      <td>6150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>6150</td>\n",
       "      <td>6151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>6151</td>\n",
       "      <td>6152</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>6152</td>\n",
       "      <td>6153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6153 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    ID  Anger  Anxiety  Expect  Hate  Joy  Love  Sorrow  \\\n",
       "0              0     1      0        0       1     0    0     0       0   \n",
       "1              1     2      0        0       1     0    0     0       0   \n",
       "2              2     3      1        1       0     0    0     0       0   \n",
       "3              3     4      1        1       0     1    0     0       0   \n",
       "4              4     5      0        0       0     0    0     0       1   \n",
       "...          ...   ...    ...      ...     ...   ...  ...   ...     ...   \n",
       "6148        6148  6149      0        0       0     0    0     1       0   \n",
       "6149        6149  6150      0        0       1     0    0     1       0   \n",
       "6150        6150  6151      0        0       0     0    1     1       0   \n",
       "6151        6151  6152      0        1       0     0    0     0       0   \n",
       "6152        6152  6153      0        1       0     0    0     0       0   \n",
       "\n",
       "      Surprise  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "6148         0  \n",
       "6149         0  \n",
       "6150         0  \n",
       "6151         0  \n",
       "6152         0  \n",
       "\n",
       "[6153 rows x 10 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('./test1.csv')\n",
    "test = test.drop('Text',axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1bd8ac8e-adb8-4ea7-8aff-18fa44c851d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anger</th>\n",
       "      <th>Anxiety</th>\n",
       "      <th>Expect</th>\n",
       "      <th>Hate</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Love</th>\n",
       "      <th>Sorrow</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6153 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Anger  Anxiety  Expect  Hate  Joy  Love  Sorrow  Surprise\n",
       "0         0        0       1     0    0     0       0         0\n",
       "1         0        0       1     0    0     0       0         0\n",
       "2         1        1       0     0    0     0       0         0\n",
       "3         1        1       0     1    0     0       0         0\n",
       "4         0        0       0     0    0     0       1         0\n",
       "...     ...      ...     ...   ...  ...   ...     ...       ...\n",
       "6148      0        0       0     0    0     1       0         0\n",
       "6149      0        0       1     0    0     1       0         0\n",
       "6150      0        0       0     0    1     1       0         0\n",
       "6151      0        1       0     0    0     0       0         0\n",
       "6152      0        1       0     0    0     0       0         0\n",
       "\n",
       "[6153 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = test.loc[ : , \"Anger\":\"Surprise\"]\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fa7a1f19-4b0f-446e-81d9-49e26fbbd8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Anger': 0,\n",
       " 'Anxiety': 0,\n",
       " 'Expect': 1,\n",
       " 'Hate': 0,\n",
       " 'Joy': 0,\n",
       " 'Love': 0,\n",
       " 'Sorrow': 0,\n",
       " 'Surprise': 0}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(test1.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a303cee-9ebc-43df-9ef2-ed7fe613ea3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'Anger'\", \"'Anxiety'\"]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据值来查找键\n",
    "def get_keys(d, value):\n",
    "    return [\"'\" + k + \"'\" for k, v in d.items() if v == value]\n",
    "\n",
    "# keys = []\n",
    "# 找出值为2的键\n",
    "keys = get_keys(dict(test1.iloc[2]), 1)\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ccbad40-ece8-4142-a5b3-2c15acacf2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         ['Expect']\n",
       "1                         ['Expect']\n",
       "2               ['Anger', 'Anxiety']\n",
       "3       ['Anger', 'Anxiety', 'Hate']\n",
       "4                         ['Sorrow']\n",
       "                    ...             \n",
       "6148                        ['Love']\n",
       "6149              ['Expect', 'Love']\n",
       "6150                 ['Joy', 'Love']\n",
       "6151                     ['Anxiety']\n",
       "6152                     ['Anxiety']\n",
       "Length: 6153, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test1.apply(lambda x: get_keys(dict(x), 1), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ba3cda6-4401-494a-9fe0-b8518f2be13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.concat([test['ID'],df], axis=1)\n",
    "test2.columns=['ID','Labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5bf64b63-4827-4d9f-b704-7279936b702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.to_csv('./test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd42528-f9e5-41c3-bbe9-9bc3df9dce87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e9a74c3-246b-490a-9b6a-3d5729116034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -i https://pypi.tuna.tsinghua.edu.cn/simple transformers\n",
    "\n",
    "# import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "289b5aee-d6c8-4428-b83c-ef81b3e92787",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Collecting pytorch-pretrained-bert\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex in /root/miniconda3/lib/python3.8/site-packages (from pytorch-pretrained-bert) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.8/site-packages (from pytorch-pretrained-bert) (4.61.2)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (from pytorch-pretrained-bert) (2.25.1)\n",
      "Collecting boto3\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/c7/dd/4fe47b2cec8731ec26d7410e659c4f0c4cd36baa835e2312cb0ec5383b07/boto3-1.28.65-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 64.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /root/miniconda3/lib/python3.8/site-packages (from pytorch-pretrained-bert) (1.21.5)\n",
      "Requirement already satisfied: torch>=0.4.1 in /root/miniconda3/lib/python3.8/site-packages (from pytorch-pretrained-bert) (1.10.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.0.0)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/31/b4/b9b800c45527aadd64d5b442f9b932b00648617eb5d63d2c7a6587b7cafc/jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting boto3\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/50/58/2324b65441c0f83013d27ad8e4b614688d4dd79237ff43d1488dfcc01f3b/boto3-1.28.64-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 47.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.32.0,>=1.31.64\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/63/c6/8e29a2b9dffa188d07c26d19ae578a26d8063834e4d844bf22c2a0028229/botocore-1.31.65-py3-none-any.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 16.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting boto3\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/c0/67/4d23a38313d7b37892a6d9c9260809f1a2f5a37feaf6f13da0aa27f57d6d/boto3-1.28.63-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 13.5 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/63/e5/8fc4a69186cb15b0dba9c428da73233c89eb18ee03ce56f6bde205ea2006/boto3-1.28.62-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 38.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/4d/65/a0927694bb02d8ae46c399d9a8ed2cd9c724adbc9bbb7849a0650850ad31/boto3-1.28.61-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 41.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/da/7e/ea3b898a2f7f8b698eb93d808cca4202e2e5ee1887715b28b42fb9b5c71c/boto3-1.28.60-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 42.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/88/a3/e63a11c957c1e2a901d13f3ddc2acba2d0db8a7bcbac2e3f5b06aab0c6de/boto3-1.28.59-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 39.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/90/ca/a9e28e3d0c924743d8086de1ba9afae1406ac2811cf809abac5c69467a57/boto3-1.28.58-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 83.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/91/a9/c6eea6c80c57d8957eaba3cc1122339a1adbdce60532cbf94046c312bcd3/boto3-1.28.57-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 64.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/9b/86/1c5a07d3c93e80b22e6dce8c2280199e6e12dbf72dd8738d4f5e65887bc8/boto3-1.28.56-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 63.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/1e/3e/827f665b39f95c74d040d4745fdbb9f1097e40ef705fac2ef0eaa3f63f6a/boto3-1.28.55-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 77.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading https://repo.huaweicloud.com/repository/pypi/packages/60/d0/9ce6abb39e0c037028172ad3465e76ac9c8ed39095028109fe7c54e8aa28/boto3-1.28.54-py3-none-any.whl (135 kB)\n",
      "\u001b[K     |████████████████████████████████| 135 kB 31.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading https://repo.huaweicloud.com/repository/pypi/packages/d9/17/a3b666f5ef9543cfd3c661d39d1e193abb9649d0cfbbfee3cf3b51d5af02/s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 19.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.25.4 in /root/miniconda3/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.64->boto3->pytorch-pretrained-bert) (1.26.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /root/miniconda3/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.64->boto3->pytorch-pretrained-bert) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.64->boto3->pytorch-pretrained-bert) (1.16.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /root/miniconda3/lib/python3.8/site-packages (from requests->pytorch-pretrained-bert) (4.0.0)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
      "Successfully installed boto3-1.28.54 botocore-1.31.65 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef38f5cf-899d-4e1f-9378-b0abf735c38b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.8765,  0.0977, -0.3460,  ...,  0.5527,  0.0241, -0.2857],\n",
      "         [-0.8829,  0.2881,  0.0876,  ...,  0.2261, -0.3675, -0.3354],\n",
      "         [-0.3034,  0.3377,  0.6217,  ..., -0.3015,  0.2828,  0.0967],\n",
      "         ...,\n",
      "         [ 0.6289,  0.0569, -0.0327,  ...,  0.2157, -0.4363, -0.1250],\n",
      "         [ 0.0912,  0.2132, -0.7634,  ...,  0.0302, -0.1138,  0.2884],\n",
      "         [-0.5577, -0.4237, -0.1272,  ...,  0.1528, -0.1279,  0.1162]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.9995,  1.0000,  0.9949,  0.8371,  0.5831,  0.5679, -0.4190, -0.9272,\n",
      "          0.9958, -0.9588,  1.0000,  0.9994, -0.0425, -0.9962,  0.9999, -0.9988,\n",
      "         -0.9984,  0.9786,  0.9971, -0.1568,  0.9998, -1.0000, -0.9813, -0.5638,\n",
      "         -0.1753,  0.9740,  0.8660, -0.0171, -0.9998,  0.9819,  0.9332,  0.9991,\n",
      "          0.9558, -0.9999, -0.9920, -0.3774, -0.3995,  0.9865, -0.7910, -0.7119,\n",
      "         -0.9659, -0.6644, -0.4246, -0.9824, -0.9884,  0.8382, -1.0000, -0.9999,\n",
      "          0.5832,  0.9998, -0.7969, -0.9995,  0.8764, -0.8718, -0.8651,  0.9694,\n",
      "         -0.9989,  0.8391,  1.0000,  0.9838,  0.9997, -0.9056, -0.2356, -0.9981,\n",
      "          1.0000, -0.9996, -0.8970,  0.0628,  0.9999,  1.0000, -0.9719,  0.9704,\n",
      "          1.0000,  0.3417,  0.2441,  0.9989, -0.9911,  0.8484, -1.0000,  0.5090,\n",
      "          1.0000,  0.9994, -0.9602,  0.9798, -0.9856, -0.9999, -0.9999,  0.9919,\n",
      "         -0.4758,  0.9992,  0.9850, -0.9968, -1.0000,  0.9942, -0.9994, -0.9975,\n",
      "         -0.2948,  0.9927, -0.4319, -0.7895, -0.9225,  0.6141, -0.9954, -0.9946,\n",
      "          0.9707,  0.9996,  0.9262, -0.9953,  0.9996,  0.4721, -1.0000, -0.9579,\n",
      "         -0.9997, -0.8475, -0.9815,  1.0000,  0.9277,  0.2862,  0.9990, -0.9933,\n",
      "          0.8959, -0.9995, -0.8935, -0.5176,  0.9988,  1.0000,  0.9924, -0.9980,\n",
      "          0.9989,  1.0000,  0.8805,  0.8685, -0.9732,  0.9793,  0.9636, -0.9962,\n",
      "         -0.2782, -0.8543,  1.0000,  0.9383,  0.8793, -0.9155,  0.9980, -0.9757,\n",
      "          0.9999, -0.9999,  0.9981, -1.0000, -0.9985,  0.9984,  0.9940,  1.0000,\n",
      "         -0.9126,  0.9999, -0.8853, -0.9993,  0.9996, -0.3936,  0.9962, -1.0000,\n",
      "          0.9872, -0.8519,  0.4259,  0.6453, -1.0000,  0.9999, -0.8821,  1.0000,\n",
      "          0.9986, -0.9967, -0.9956, -0.9697,  0.0975, -0.9942, -0.9625,  0.9035,\n",
      "          0.5466,  0.9955, -0.8590, -0.9944,  0.9969, -0.8243, -0.9999,  0.9919,\n",
      "         -0.5897,  0.6820, -0.4187,  0.8055,  0.9977,  0.9813, -0.7977,  1.0000,\n",
      "          0.5023,  0.9991,  0.9918,  0.1197,  0.1535, -0.9151, -1.0000,  0.5651,\n",
      "          0.9999, -0.7257, -0.9979,  0.9029, -1.0000,  0.9680, -0.8868,  0.7947,\n",
      "         -0.9988, -0.9999,  1.0000, -0.9923, -0.9926,  0.9417, -0.9746,  0.2991,\n",
      "         -0.9993, -0.0432,  0.9869, -0.8920,  0.2155, -0.4244, -0.9951,  0.9997,\n",
      "         -0.9983,  0.9029,  0.9950,  1.0000,  0.8098, -0.5845, -0.8818,  0.9998,\n",
      "          0.5090, -1.0000,  0.8959, -0.9989, -0.9626,  0.9999, -0.9984,  0.9960,\n",
      "          1.0000,  0.8465,  1.0000,  0.5606, -0.9994, -0.9986,  1.0000,  0.9954,\n",
      "          0.9999, -0.9963, -0.9993, -0.2656,  0.0163, -1.0000, -0.9996, -0.6342,\n",
      "          0.9942,  1.0000, -0.4775, -0.9995, -0.9419, -0.9973,  1.0000, -0.4106,\n",
      "          1.0000,  0.9946, -0.9685, -0.9985,  0.9302, -0.5222, -0.9994,  0.2313,\n",
      "         -0.9996, -0.9258, -0.9999,  0.9690, -0.9973, -1.0000,  0.9320,  1.0000,\n",
      "          0.9680, -0.9998,  0.9907,  0.9945, -0.9942, -0.9874,  0.9748, -1.0000,\n",
      "          1.0000, -0.9955,  0.4375, -0.9783, -0.9960, -0.5634,  0.9992,  0.9977,\n",
      "         -0.9927, -0.9807, -0.9855, -0.9999, -0.5568,  0.9057, -0.7676,  0.8366,\n",
      "         -0.9347, -0.9876,  0.9439, -0.9981, -0.9997,  0.4018,  1.0000,  0.0760,\n",
      "          1.0000,  0.4031,  1.0000,  0.8322, -0.9505,  0.9882, -0.9112, -0.7451,\n",
      "         -0.9555, -0.9803,  0.3919,  0.5395, -0.1052, -0.9997,  0.9999,  0.9993,\n",
      "          0.8746,  0.8793, -0.8271, -0.7648,  0.8024, -0.9605,  0.9986, -0.9994,\n",
      "         -0.0112,  0.9998,  1.0000,  0.9994,  0.5760, -0.9298,  0.9930, -0.9914,\n",
      "          0.9968, -0.9996,  0.9982, -0.9851, -0.0277, -0.3419, -0.9868,  1.0000,\n",
      "          0.9146, -0.6093,  0.9998, -0.8994,  0.9981,  0.9933,  0.9794,  0.9728,\n",
      "          0.1324,  0.9999, -0.9932, -0.9980, -0.3567, -0.9974, -0.9981, -1.0000,\n",
      "          0.1203, -0.9983, -0.9893, -0.6620,  0.6180,  0.7697, -0.8769, -0.3038,\n",
      "          0.2146,  0.7065, -0.9547,  0.6975,  0.9805, -0.9989, -0.8978, -1.0000,\n",
      "         -0.9966,  0.9149,  0.9995, -0.9998,  0.9963, -1.0000, -0.9623,  0.9490,\n",
      "          0.5162,  0.2273,  0.9998, -0.9999,  0.8068,  0.9996,  1.0000,  0.9954,\n",
      "          0.9998, -0.7728, -0.9997, -0.9990, -0.9999, -1.0000, -0.9996, -0.5822,\n",
      "          0.9880, -1.0000, -0.9082,  0.9544,  1.0000,  0.9103, -0.9998, -0.3333,\n",
      "         -0.9978, -0.9961,  0.9957, -0.9944, -0.9992,  0.9847,  0.2515,  0.9999,\n",
      "         -0.7297,  0.9495,  0.9753,  0.6476,  0.2494, -1.0000,  0.5549,  1.0000,\n",
      "          0.4525, -1.0000, -0.8125, -0.8923, -0.9998, -0.3507,  0.9132,  0.9973,\n",
      "         -1.0000, -0.9206, -0.9987,  0.6162,  0.9260,  0.9962,  0.9994,  0.9937,\n",
      "          0.9568,  0.9957, -0.6452,  0.9999,  0.8414, -0.9994,  0.9930, -0.0785,\n",
      "          0.7327, -0.9997,  0.9900,  0.8868,  0.9999,  0.9996, -0.7612, -0.9973,\n",
      "         -0.9715,  0.9899,  1.0000, -0.8461, -0.4685, -0.9993, -0.9998, -0.9965,\n",
      "         -0.8523, -0.8758, -0.9828, -0.9996,  0.1538,  0.5862,  1.0000,  0.9999,\n",
      "          0.9979, -0.9333, -0.9586,  0.9940,  0.5334,  0.9949, -0.9235, -1.0000,\n",
      "         -0.9964, -0.9997,  0.9998,  0.9093,  0.2718, -0.8994,  0.7947,  0.8775,\n",
      "         -0.9997, -0.9811, -0.9969, -0.5210,  1.0000, -0.9997,  0.9974, -0.9841,\n",
      "          0.1553,  0.8972,  0.7516,  0.9987, -0.1557,  0.0427, -0.8583,  0.9713,\n",
      "          0.9751,  0.9971, -0.9938,  0.7032,  0.9943, -0.9863,  0.9996,  0.5591,\n",
      "          0.4885,  0.9618,  1.0000, -0.7277,  0.9999,  0.9942,  0.9999,  0.9999,\n",
      "         -0.9844,  0.5928,  0.2515, -0.4208, -0.7714,  0.9436,  1.0000,  0.8454,\n",
      "         -0.9972, -0.9999,  0.9844,  0.9998,  1.0000, -0.0549,  0.9997, -0.9016,\n",
      "          0.7611,  0.9461,  0.2921,  0.1619,  0.7087,  0.9863,  0.9924, -0.9999,\n",
      "         -1.0000, -1.0000,  1.0000,  0.9983,  0.3858, -1.0000,  0.9988, -0.1279,\n",
      "          0.9986,  0.9951,  0.1971, -0.9764,  0.6485, -0.9981,  0.3779,  0.9371,\n",
      "          0.1237,  0.6499,  0.9899, -0.9960, -0.1021,  1.0000,  0.0784,  0.9999,\n",
      "          0.5872, -0.9995,  0.9993, -0.9962, -0.9998, -0.7480,  0.9997,  0.9995,\n",
      "         -0.4983,  0.3475,  0.9999, -0.9990,  1.0000, -0.9999,  0.6537, -0.9987,\n",
      "          0.9999, -0.9807, -0.9992, -0.8345, -0.2524,  0.9822, -0.2054,  0.9999,\n",
      "          0.0753, -0.7606, -0.3084, -0.9925, -0.9978, -0.9912,  0.8254, -1.0000,\n",
      "          0.7180,  0.3098, -0.3283, -0.3842, -1.0000,  0.9999, -0.8948, -0.9765,\n",
      "          0.9999, -0.9995, -1.0000,  0.9920, -0.9553, -0.2919,  0.9925,  0.9139,\n",
      "         -0.0251, -1.0000,  0.8351,  0.9997, -0.9969, -0.9072, -0.9563, -0.9537,\n",
      "          0.9386,  0.9886,  0.9005, -0.1566,  0.9268,  0.9961,  0.4664,  0.2883,\n",
      "          0.7765, -0.9998, -0.9978, -0.9678, -0.9932, -0.9997, -0.9999,  1.0000,\n",
      "          0.9999,  1.0000,  0.8261, -0.9652,  0.5566,  0.9824, -0.9996, -0.8950,\n",
      "          0.8322,  0.6920, -0.8903, -0.9988, -0.6515, -1.0000, -0.4366,  0.2288,\n",
      "         -0.9902,  0.4479,  1.0000,  0.9998, -0.9995, -0.9930, -0.9918, -0.9973,\n",
      "          0.9999,  0.9973,  0.9973, -0.9205, -0.7321,  0.9445, -0.7920,  0.2110,\n",
      "         -0.9990, -0.9832, -0.9999,  0.9489, -0.9987, -0.9998,  0.9971,  0.9999,\n",
      "          0.9209, -0.9999, -0.5193,  0.9999,  0.9912,  1.0000,  0.5892,  0.9998,\n",
      "         -0.9954,  0.9994, -0.9999,  1.0000, -1.0000,  1.0000,  1.0000,  0.9710,\n",
      "          0.9987, -0.9990,  0.9728,  0.3417, -0.7432,  0.8835, -0.6931, -0.9979,\n",
      "          0.8831,  0.9894, -0.4353,  1.0000,  0.9839,  0.8086,  0.9547, -0.8829,\n",
      "          0.9991, -0.3561, -0.9979,  0.9995,  0.9992,  0.9874,  1.0000,  0.9653,\n",
      "          1.0000, -0.9839, -0.9964,  0.8947, -0.4836,  0.8276, -0.9999,  1.0000,\n",
      "          0.9998, -0.9993, -0.5650, -0.1052,  0.7907,  0.9999,  0.9972,  0.9576,\n",
      "          0.9393, -0.5280,  0.9985, -0.9944, -0.4096, -0.9952, -0.4396,  1.0000,\n",
      "         -0.7716,  0.9993, -0.9960,  0.9992, -0.9900,  0.9637,  0.9926,  0.9881,\n",
      "         -0.9985,  1.0000,  0.7031, -0.9938, -0.9983, -0.9985, -0.9945, -0.4782]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"./model/bert-base-chinese\")\n",
    "# model = BertModel.from_pretrained(\"./model/bert-base-chinese\")\n",
    "\n",
    "# # ...一系列操作\n",
    "# text = \"Replace me by any text you'd like.\"\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# output = model(**encoded_input)\n",
    "# print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b60d2aa8-b346-4f06-8f6c-0e6a7cdc1784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "682bcaee-4b90-453e-9d4b-e87c10f2b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2b91139-bf84-47a7-8a7c-e411b397e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbca53bc-24e8-461e-bac9-fc2c3f4297e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# import scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfadba1a-4f2c-43ec-bf1a-35af71fefe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c508f4c-fc2f-4001-8304-b45b1c4c5d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
